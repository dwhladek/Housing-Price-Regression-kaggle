{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices: Advanced Regression Techniques\n",
    "\n",
    "#### Competition Description\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal \n",
    "\n",
    "To predict the sales price for each house. For each ID in the test set, you must predict the value of the SalePrice variable\n",
    "\n",
    "### Metric\n",
    "\n",
    "Submission are evaluated on the Root-Mean-Squared-Error(RMSE) between the logarithm of the predicted value and logarithm of the observed sales price. \n",
    "**(Taking logs means that errors in predicting the expensive houses and cheap houses will effect the result equally)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes from description\n",
    "- YearRmodeladd is the same year if there have been no remodel or additions (need to change this to 0)\n",
    "- There are Total Rooms and Bedrooms, don't confuse them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "import datetime as dt\n",
    "import math\n",
    "from math import radians, cos, sin, asin,sqrt\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#import plotly\n",
    "#plotly.tools.set_credentials_file(username='peanuttbuddha', api_key='NJTdnmJo7EwDcaxEL9mO')\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import chartify\n",
    "# NOTE THAT INLINE NEEDS TO BE LAST\n",
    "%matplotlib inline\n",
    "# Missing Data Visualization\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because of the plots below I will get rid of any values where sqft > 4000 and sale price < 500k (just those 2 datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(train[((train['GrLivArea']>4000) & (train['SalePrice']<300000))].index)\n",
    "train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is a lot of information. Let's start with finding and filling missing values and then run the report again\n",
    "- Alley has 2721 / 93.2% missing values Missing\n",
    "- BsmtCond has 82 / 2.8% missing values Missing\n",
    "- BsmtExposure has 82 / 2.8% missing values Missing\n",
    "- BsmtFinType1 has 79 / 2.7% missing values Missing\n",
    "- BsmtFinType2 has 80 / 2.7% missing values Missing\n",
    "- BsmtUnfSF 1 missing values Missing\n",
    "- BsmtFinSF1 1 missing values Missing\n",
    "- BsmtFinSF2 1 missing values Missing\n",
    "- BsmtQual has 81 / 2.8% missing values Missing\n",
    "- Fence has 2348 / 80.4% missing values Missing\n",
    "- FireplaceQu has 1420 / 48.6% missing values Missing\n",
    "- GarageCond has 159 / 5.4% missing values Missing\n",
    "- GarageFinish has 159 / 5.4% missing values Missing\n",
    "- GarageQual has 159 / 5.4% missing values Missing\n",
    "- GarageType has 157 / 5.4% missing values Missing\n",
    "- GarageYrBlt has 159 / 5.4% missing values Missing\n",
    "- LotFrontage has 486 / 16.6% missing values Missing\n",
    "- MiscFeature has 2814 / 96.4% missing values Missing\n",
    "- PoolQC has 2909 / 99.7% missing values Missing\n",
    "- SalePrice has 1459 / 50.0% missing values Missing\n",
    "<br>\n",
    "\n",
    "**Breaking Down null values** <br>\n",
    "1. null values where we know we can just impute 'None'\n",
    "    - Alley we can impute NaN with None, since we can assume they don't have an alley\n",
    "    - Fence we can also do the same\n",
    "    - MiscFeature we can also do the same\n",
    "    - FireplaceQu we can also do the same since we can see that the 'Fireplaces' column has 1420 zeros and FireplaceQu has 1420 NaN\n",
    "2. Null Values where we need to do more investigation\n",
    "    - **PoolQC.** We have 13 non 0 values in the Pool Area and only 10 values for PoolQC, meaning there are 3 PoolQC values that are not 'None', so first we need to find the rows that have PoolArea filled in where PoolQC are null and fill those in somehow, then we can impute the rest with 'None'\n",
    "    - **Bsmt stuff**\n",
    "    - **Garage stuff**\n",
    "    - **LotFrontage** Possibly bin LotArea and take the average based on that\n",
    "    - **Function**\n",
    "    - **KitchenQual**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that I removed a lot of the code that where I imputed values because it is mostly the same for each feature that I changed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with filling in PoolQC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.PoolArea!=0) & (data.PoolQC.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some graphs to see if I can impute these by that information\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "sns.boxplot(x='PoolQC', y='PoolArea', data=data, ax=ax1)\n",
    "ax2 = fig.add_subplot(122)\n",
    "sns.boxplot(x='PoolQC', y='SalePrice', data=data, ax=ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There aren't a lot of values in this category, so It doesn't matter too much but based on these graphs I'll fill the smaller pool area values with 'Ex' and the 561 pool area with 'Fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the specific null values to 'Ex' or 'Fa'\n",
    "data['PoolQC'].loc[(data['PoolQC'].isnull()) & (data['PoolArea'] < 500) & (data['PoolArea'] !=0)] = 'Ex'\n",
    "data['PoolQC'].loc[(data['PoolQC'].isnull()) & (data['PoolArea'] > 500)] = 'Fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to make sure we are ready to fill in na values with 0 or none\n",
    "updated_list_of_na_columns = data.columns[data.isna().any()].tolist()\n",
    "updated_list_of_na_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data is ready for the mass fill besides LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to pull out SalePrice \n",
    "lot_frontage = data['LotFrontage']\n",
    "del data['LotFrontage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass filling in of null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to drop saleprice first so we can keep those as nans\n",
    "target= data['SalePrice']\n",
    "del data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Comprehension to fill in the null values, if column is Object fillna with None, else fillna with 0\n",
    "# assigning it to a random variable so 'none' doesn't get printed a million times\n",
    "_ = [data[col].fillna('None', inplace=True) if (data[col].dtype=='O') else data[col].fillna(0, inplace=True) for col in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and add back in so we can explore the data\n",
    "data=data.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "- Before I impute Lot frontage with ML I want to explore the data a little\n",
    "- In this case I don't want to take dummies on objects yet because I want to explore some of the categorical variables as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since There are a lot of things to compare I will create a function for simple plotly graphs so I can call it whenever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do try and except and also multiple kwargs\n",
    "def plotly_plot(df, colx, coly, chart_type,**kwargs):\n",
    "    #try:\n",
    "        #print (go.chart_type)\n",
    "        trace = chart_type(x=df[colx], y=df[coly], **kwargs)\n",
    "        plot = [trace]\n",
    "        layout = go.Layout(\n",
    "                xaxis=dict(\n",
    "                    title = colx,\n",
    "                        titlefont=dict(\n",
    "                            family='Courier New, monospace',\n",
    "                                size=18,\n",
    "                                    color='#000000'\n",
    "                        )\n",
    "                ),\n",
    "                yaxis = dict(\n",
    "                    title=coly,\n",
    "                        titlefont=dict(\n",
    "                            family='Courier New, monospace',\n",
    "                                size=18,\n",
    "                                    color='#000000'\n",
    "                        )\n",
    "                )\n",
    "        )\n",
    "        fig=dict(data=plot,layout=layout)\n",
    "        return offline.iplot(fig)\n",
    "    #except:\n",
    "        #print('Please use (go.) before your chart_type of choice')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'OverallCond', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Its really interesting to see the outliers at the 5 and 6 overallcond. Higher OverallCond does not mean higher price\n",
    "#### Lets check OverallQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'OverallQual', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So here we see the trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking to see if there is a relationship between bedrooms(above ground) and sale price\n",
    "plotly_plot(data, 'BedroomAbvGr', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about Total Rooms?\n",
    "plotly_plot(data, 'TotRmsAbvGrd', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### somewhat of a Trend. This makes me think about rooms and sqft.\n",
    "- Id assume there is a relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'TotRmsAbvGrd', 'GrLivArea', go.Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_bath_group = data.groupby('BedroomAbvGr', as_index=False)['FullBath'].agg('mean')\n",
    "plotly_plot(bed_bath_group, 'BedroomAbvGr', 'FullBath',go.Scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up groupbys for the chart\n",
    "max_bath_group = data.groupby('BedroomAbvGr', as_index=False)['FullBath'].agg('max')\n",
    "avg_bath_group = data.groupby('BedroomAbvGr', as_index=False)['FullBath'].agg('mean')\n",
    "min_bath_group = data.groupby('BedroomAbvGr', as_index=False)['FullBath'].agg('min')\n",
    "# Create and style traces\n",
    "trace0 = go.Scatter(\n",
    "    x = max_bath_group['BedroomAbvGr'],\n",
    "    y = max_bath_group['FullBath'],\n",
    "    name = 'Max baths',\n",
    "    line = dict(\n",
    "        color = ('rgb(76, 153, 0)'),\n",
    "        width = 4)\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = avg_bath_group['BedroomAbvGr'],\n",
    "    y = avg_bath_group['FullBath'],\n",
    "    name = 'Avg Baths',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 4,)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = min_bath_group['BedroomAbvGr'],\n",
    "    y = min_bath_group['FullBath'],\n",
    "    name = 'Min baths',\n",
    "    line = dict(\n",
    "        color = ('rgb(205, 12, 24)'),\n",
    "        width = 4,\n",
    "        dash = 'dash') # dash options include 'dash', 'dot', and 'dashdot'\n",
    ")\n",
    "\n",
    "plot = [trace0, trace1, trace2]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Min, Avg, and Max bathrooms per bedrooms',\n",
    "              xaxis = dict(title = 'Bedrooms(Above Ground)'),\n",
    "              yaxis = dict(title = 'Baths'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=plot, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting that some places dont have bathrooms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.FullBath ==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.FullBath==0) & (data.BsmtFullBath ==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These residences do have bathrooms, theyre just in the basement. I can assume these are solid data points\n",
    "#### Even the one above has some half baths(I'm assuming it could be 3/4 baths?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 Bedrooms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.BedroomAbvGr==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### They all have fairly large FINISHED basements. This is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'FullBath', 'GrLivArea', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible Outliers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'GrLivArea', 'SalePrice',go.Scatter, mode='markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly a trend here. \n",
    "- Are there outliers we need to get rid of?\n",
    "    - I think we should get rid of any sqft > 4000 and any sale price > 500k\n",
    "    - **We need to do this on the train set**! ^ up above I will do it\n",
    "#### For fun I'm going to add in LotArea and do a 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'GrLivArea', 'LotArea', go.Scatter3d, mode='markers', z=data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_sf_group = data.groupby('OverallQual', as_index=False )['GrLivArea'].agg('mean')\n",
    "plotly_plot(qual_sf_group, 'OverallQual', 'GrLivArea', go.Bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curious if there are any houses where the basement is larger than the 1stFloorSF, that would be weird?\n",
    "plotly_plot(data, '1stFlrSF', 'TotalBsmtSF', go.Scatter, mode='markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are some, but theres a pretty linear relationship like I thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby to get average\n",
    "month_sold_group = data.groupby('MoSold', as_index=False)['SalePrice'].agg('mean')\n",
    "plotly_plot(month_sold_group, 'MoSold', 'SalePrice', go.Scatter, mode='lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting, There is no real correlation between sale price and month, this also shows us that we need to get dummies on 'MoSold'\n",
    "#### Going to add in min and max per month and see what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up groupbys for the chart\n",
    "max_sold_group = data.groupby('MoSold', as_index=False)['SalePrice'].agg('max')\n",
    "avg_sold_group = data.groupby('MoSold', as_index=False)['SalePrice'].agg('mean')\n",
    "min_sold_group = data.groupby('MoSold', as_index=False)['SalePrice'].agg('min')\n",
    "# Create and style traces\n",
    "trace0 = go.Scatter(\n",
    "    x = max_sold_group['MoSold'],\n",
    "    y = max_sold_group['SalePrice'],\n",
    "    name = 'Max Sale Price',\n",
    "    line = dict(\n",
    "        color = ('rgb(76, 153, 0)'),\n",
    "        width = 4)\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = avg_sold_group['MoSold'],\n",
    "    y = avg_sold_group['SalePrice'],\n",
    "    name = 'Avg Sale Price',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 4,)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = min_sold_group['MoSold'],\n",
    "    y = min_sold_group['SalePrice'],\n",
    "    name = 'Min Sale Price',\n",
    "    line = dict(\n",
    "        color = ('rgb(205, 12, 24)'),\n",
    "        width = 4,\n",
    "        dash = 'dash') # dash options include 'dash', 'dot', and 'dashdot'\n",
    ")\n",
    "\n",
    "plot = [trace0, trace1, trace2]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Min, Avg, and Max Sale Prices per month',\n",
    "              xaxis = dict(title = 'Month'),\n",
    "              yaxis = dict(title = 'Sale Price'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=plot, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting to see the variance in the max values, but mostly the average doesn't vary too much. Further proof we need to convert MoSold to a string and then take dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'YrSold', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Strange that YrSold does not effect sale price at all\n",
    "- Should change this to Categorical and take dummies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot(data, 'Neighborhood', 'SalePrice', go.Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "1. replacing year with 0 if yearremodadd=yrbuilt(should not have a value if never remodeled\n",
    "2. changing numeric col to str(to take dummies)\n",
    "3. TotalSF = GrlivArea + TotalBsmtSF\n",
    "4. GrLivArea/ LotArea\n",
    "5. Lot frontage/lot area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. If yearremodadd = yearbuilt, replace value in yearremodadd with 0(according to docs this means there was no remodel)\n",
    "- Surprisingly this did not really do anythin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if year built and remodadd are the same replace yearremodadd with 0. They should not have a value if theyve never been remodeled\n",
    "data['YearRemodAdd']= np.where(data.YearRemodAdd == data.YearBuilt, 0, data.YearRemodAdd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Changing stuff to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change MoSold from int to a String so you can take dummies(based on chart above)\n",
    "def turn_obj(cols):\n",
    "    for col in cols:\n",
    "        data[col] = data[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_obj(['MoSold', 'YrSold', 'OverallCond', 'MSSubClass', 'GarageCars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Total Sq ft(including basement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalSF'] = data['GrLivArea'] + data['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sq ft divided by Lot Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['totalSF_by_LotArea'] = data['TotalSF'] / data['LotArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ID!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to drop SalePrice because it has NaNs and we dont want it in the algo to impute LotFrontage\n",
    "# will create target again, just because\n",
    "target = data['SalePrice']\n",
    "missing_sales = data[data['SalePrice'].isnull()]\n",
    "sub_id = missing_sales['Id']\n",
    "# delete so its not used\n",
    "#del data['Id']\n",
    "data.drop(['SalePrice', 'Id'], axis=1,inplace=True)\n",
    "# Bring in LotFrontage\n",
    "data=data.join(lot_frontage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Neighborhood')['LotFrontage'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try mean and median, see what works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will first impute missing lotfrontage values with the mean based on the neighborhood\n",
    "data['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 more piece of feature engineering\n",
    "data['lotarea-frontage'] = data['LotFrontage'] / data['LotArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is anything too correlated with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Labelencoding, as it has worked for mls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "cols_for_label = ['BsmtCond', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','Condition1', \n",
    "                  'Condition2', 'ExterQual', 'GarageCond', 'GarageQual', 'GarageType', 'KitchenQual', 'LotShape', \n",
    "                 'LotConfig', 'MiscFeature', 'PavedDrive', 'Functional', 'Fence', 'Alley', 'YearRemodAdd']\n",
    "# loop to use labelencoder on the chosen columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "for col in cols_for_label:\n",
    "    le.fit(data[col])\n",
    "    list(le.classes_)\n",
    "    data[col] = le.transform(data[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now to check distribution/ skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_no_nan = target.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code taken from another user here on kaggle. Great stuff thank you!\n",
    "def check_skewness(df):\n",
    "    sns.distplot(df, fit = norm);\n",
    "    fig =plt.figure(figsize=(16,8))\n",
    "    res = stats.probplot(df, plot=plt)\n",
    "    # get fitted parameters used by the function\n",
    "    (avg, std) = norm.fit(df)\n",
    "    print ('\\n avg = {:.2f} and std = {:.2f}\\n' .format(avg, std))\n",
    "check_skewness(target_no_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_no_nan = np.log1p(target_no_nan)\n",
    "\n",
    "check_skewness(target_no_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Skew For Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = data.dtypes[data.dtypes != 'object'].index\n",
    "#check skew\n",
    "skewed_feats = data[num_feats].apply(lambda x:skew(x)).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'sKew':skewed_feats})\n",
    "#skewness = skewness.drop(['price'])\n",
    "skewness.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Skew For Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxcox fix skew\n",
    "skewness = skewness[abs(skewness) > .75]\n",
    "print (skewness.shape[0])\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = .15\n",
    "for feat in skewed_features:\n",
    "    data[feat] = boxcox1p(data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(target_no_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df):\n",
    "    future_drop = [col for col in df if df[col].dtype == 'O']\n",
    "    # I know get dummies only takes Objects but if I don't do the list comp inside it gives me a columns overlap error\n",
    "    df = df.join(pd.get_dummies(df[[col for col in df if df[col].dtype == 'O']], drop_first=True)).drop(future_drop, axis=1) \n",
    "    return df\n",
    "    #df.drop(future_drop, axis=1, inplace=True)\n",
    "#data = get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Will try a couple models and then average them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, Normalizer, MaxAbsScaler, FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_price = data[data['SalePrice'].isnull()]\n",
    "filled_price = data[data['SalePrice'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(filled_price.drop('SalePrice', axis=1),filled_price['SalePrice'], test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler was almost identical to robust but gave warnings\n",
    "# FunctionTransformer helped but not too noticeable\n",
    "# RobustScaler worked the best\n",
    "gbr=  make_pipeline(RobustScaler(),GradientBoostingRegressor(n_estimators=800, learning_rate=0.05,\n",
    "                                  max_depth=4, max_features='log2',\n",
    "                                  min_samples_leaf=8, min_samples_split=6,\n",
    "                                  loss='huber', random_state=42))\n",
    "br = make_pipeline(RobustScaler(),BayesianRidge())\n",
    "r = make_pipeline(RobustScaler(),Ridge())\n",
    "xgb = make_pipeline(RobustScaler(),XGBRegressor())\n",
    "svr =make_pipeline(RobustScaler(),SVR(kernel='linear'))\n",
    "# Lasso and enet were way off until I messed with alpha,possibly fine tuning will bring a better scores\n",
    "l = make_pipeline(RobustScaler(),Lasso(alpha=.0005))\n",
    "enet = make_pipeline(RobustScaler(), ElasticNet(alpha=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to put cross_val in the tdmassess\n",
    "def cv_score(algo):\n",
    "    rmse= np.sqrt(-cross_val_score(algo, X_train, y_train, scoring='neg_mean_squared_error', cv=5))\n",
    "    return (rmse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [gbr, br, r, xgb, svr,l, enet]\n",
    "names = ['Gradient Boosting', 'Bayesian Ridge', 'Ridge', 'XGB', 'SVR', 'Lasso','ElasticNet']\n",
    "def tDMassess_regression():\n",
    "    #fit the data\n",
    "    for i in range(len(algorithms)):\n",
    "        algorithms[i] = algorithms[i].fit(X_train,y_train)\n",
    "    cv_rmse =[]\n",
    "    rmse_train=[]\n",
    "    rmse_test=[]\n",
    "    for i in range(len(algorithms)):\n",
    "        rmse_train.append(mean_squared_error(np.expm1(y_train), np.expm1(algorithms[i].predict(X_train))) **.5)\n",
    "        rmse_test.append(mean_squared_error(np.expm1(y_test), np.expm1(algorithms[i].predict(X_test)))**.5)\n",
    "        cv_rmse.append(cv_score(algorithms[i]))\n",
    "    metrics = pd.DataFrame(columns =['RMSE_train', 'RMSE_test', 'cv_RMSE'], index=names)\n",
    "    metrics['RMSE_train'] = rmse_train\n",
    "    metrics['RMSE_test'] = rmse_test\n",
    "    metrics['cv_RMSE'] = cv_rmse\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tDMassess_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to take the average of all the models\n",
    "- not going to use SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_algs = [gbr, br, l,enet]\n",
    "def average_of_models():\n",
    "    final_pred=[]\n",
    "    for i in range(len(final_algs)):\n",
    "         final_pred.append(np.expm1(final_algs[i].predict(missing_price.drop('SalePrice', axis=1))))\n",
    "    return (sum(final_pred)/len(final_algs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = average_of_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best score on kaggle was .12425\n",
    "- No label encoder\n",
    "- and average of gbr, br, r, and xgb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] =sub_id\n",
    "submission['SalePrice'] = avg_preds\n",
    "submission.to_csv('final_sub_LE_la_enet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
